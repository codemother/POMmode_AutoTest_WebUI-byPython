# Beta1.0更新
**我做了什么：**  
1.设计了思维脑图，并尝试用思维脑图的结构对框架进行优化  
2.基本实现了数据和代码的完全分离  


**新的困惑：**  
1.我并没有完全实现预想的框架设计。我无法做到一个界面对象只用一个yaml文件来存放数据而不同的断言对象或操作流程作为一个个大类，每个大类里又有多个同类型的测试用例，这么做无法进行ddt遍历，并且设计出的代码极其繁琐，与我的设计想法不符。我最后的做法是
以界面对象分类在data区创建目录，每个目录下存放不同的断言对象或操作流程数据组成的各个yaml文件。 

2.但是这样我又发现了新的问题，即便是相同的断言对象也会存在如文本不同这样的情况，ddt遍历依然无法做到对同一个testcase代码测试如：（用户名非空，密码为空）（用户名为非空，密码错误）（用户名非空，密码输入位数不足
）这样的用例检测是否符合预期。似乎只要是断言不同，就需要设计新的用例，创建新的yaml文件（如果想用遍历的话）。  

3.于是我开始对我设计的结构产生怀疑，只要断言稍微有所不同我就需要编写不同的testcase代码，即便是一个简单的登录窗口，testcase可能高达上十条。  

4.继而我对POM和自动化测试也产生了思考和怀疑，在webui功能方面，面对大量细微差别的测试用例，设计自动化脚本是否合适？似乎自动化测试只适用于正向的流程（如正常登录），对于反向的各种反馈测试（如确认各种用户输错情况下的反馈信息）似乎并不好用？  

5.到底是我的代码水准和对yaml,ddt的理解程度欠缺还是结构设计不合理抑或是自动化测试确实存在局限性？有待后续学习研究  

ps:点击登录后会弹出滑动验证框，我一直无法定位到这个框中的元素，导致检测弹出框->等待->手动验证的想法无法实现，只能默认等待。尝试了切换iframe页的方法但显示定位不到iframe页。待解决  

# Beta2.0更新
**我做了什么：**  
1.在经过连续7个小时的学习，思考和实践后，我对整个框架的结构再次进行了深度优化，在1.0版本让我陷入困惑和矛盾的很多问题都在2.0版本得到了处理和解决，原本处于比较混沌的逻辑被再次梳理，2.0版本的逻辑思路将是清晰明了的。  

2.在2.0版本中，对于各种不同的测试用例数据要不要写一个新的的testcase方法，我的评判标准是：  
- 首先，这是不是一个新的操作流程，是==要写。  
- 如果不是，这个测试用例会不会用到新类型的断言方式（如：本来都是在原界面断言，现在需要切换iframe/句柄才能断言）或者需要断言多个地方（如：原先的testcase方法只能对一个地方断言，现在需要检测多个地方是否出现了对应元素），是==要写。  
- 我的核心思想是：如果之前的testcase方法需要被修改才能完成测试，那就要编写一个新的testcase方法  
    
3.我认为，断言的核心还是在于判断预期元素有没有出现，比如某个位置的文本是否出现、某个文本是否是预期的值、是否会跳转到新的标签页等等情况，他们最终都是要判断特定元素是否出现。  

4.这也就促成了我将很多参数转变为形参，将一些判断过程打包成方法，相当程度上拓展了测试用例脚本的泛用性，减少了测试用例脚本的代码量，减少了需要新写的testcase方法的数量。  

5.在2.0版本，面对同样的操作流程，我的一个testcase方法支持通过仅修改yaml数据实现对不同元素出现与否的断言。即便是需要断言多个元素，也只需要简单的对testcase和yaml做出一点添加即可。  

**待完善的方面：**  
1.测试报告的生成和所谓环境搭建、持续集成我还没有概念。  

2.目前只完成了login界面的部分流程和测试用例设计，距离整个UI功能测试的自动化还很远  

**新的困惑：**  
1.自动化测试的可行性分析到底如何分析，如何评判一个页面哪些功能是需要自动化的，仅仅是注册登录这些功能吗，这些UI按键的重要级别如何划分？  

2.如果测试用例和数据文件多了的话，就必然需要统一管理，我的这种结构和分类方式是否便于管理和使用？  

3.曾经我的设计理念是testcase的复用性高，同时测试用例文档便于读写。但是目前看来，似乎扩展了testcase的复用性，将大量权限给到yaml测试用例文档后，文档的复杂度会提高很多，需要有一定理解才能使用。不知道路有没有走歪。。。  

PS:在1.0版本我苦思冥想也没能确认的滑动验证框无法定位的问题，经过我对iframe、句柄、xpath等等方面的学习，终于得到了解决。然而这个问题也并不是什么iframe、元素隐藏、定位方法导致的，导致它的最终原因是浏览器没有反应过来，加上sleep完美解决。。。这同时也让我意识到了隐式等待并不能解决所有关于浏览器反应不过来之类的问题，似乎在静态界面上由js导致的动态效果它都不能起到作用。

# Beta2.1更新  
**我做了什么**  
1.千辛万苦之下终于成功让htmltestrunner成功运行，在report目录下生成对应的html测试报告。在这期间遇到的问题包括：  

- **htmltestrunner函数无法调用。**  
原因：这个模块是基于python2开发的，需要修改后才能在python3使用。  
解决方法：我索性将模块复制到框架中再修改，以文件的形式导入

- **添加相关代码后，直接在pycharm中运行，没有生成html文件。**  
原因：pycharm默认以Unittest的方式运行测试代码，`if __name__=='__main__'`后的代码根本没有被执行。  
解决方法：修改pycharm的运行配置，改为直接运行.py文件

- **以Unittest运行的方法不会报错，可以正常测试。但是直接运行文件则会报错，显示测试类下没有我定义的测试用例方法，这显然是和事实相矛盾的。**  
原因：可能涉及到`unittest.main()`源码的一些理解，因为时间关系粗看之下未能看懂，暂时未能确定明确原因，大概率是关于类的继承和调用问题  
解决方法：因未能明确原因，故放弃了在`if __name__=='__main__'`后直接添加测试执行的相关代码。查阅参考了很多资料，最终选择将测试执行代码作为一个装饰器函数，通过直接装饰类来实现以htmltestrunner的模式生成测试报告。虽然最终成功达成了目的，但是其实这么做逻辑上有一定的问题，`unittest.main()`中应当已经包含了一些测试执行的代码，再次装饰类可能存在重复或者嵌套之类的问题，具体需要详细理解源码才能确定。

- **虽然这里运行了两次测试，pycharm下也出现了两次运行结果，但是还是会提示`Ran 0 tests in 0.000s`。**
原因：涉及unittest源码，待研究

**待完善的方面**  
1.检测验证框是否出现的时候似乎可以添加显式等待来优化，计划在2.2加入

**新的困惑**  
1.Unittest的运行原理，内部源码



    


